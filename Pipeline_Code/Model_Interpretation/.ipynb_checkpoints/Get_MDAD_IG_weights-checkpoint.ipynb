{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: \n",
    "The sections of the notebook are for calculating integrated gradients (IG) weights for the consensus model:\n",
    "- 100 runs of MD-AD training --> Gene to phenotype importance\n",
    "- Consensus embeddings --> Gene to (consensus) node importance \n",
    "\n",
    "The IG files take up a LOT of space (Around 350GB) for outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use this code to get IG weights for each sample:\n",
    "\n",
    "Output layer: \n",
    "save 1 x N x G matrix for each phenotype\n",
    "\n",
    "Last shared layer:\n",
    "save 1 x N x G matrix for each node separately "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras import optimizers, regularizers, losses\n",
    "\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras import metrics\n",
    "\n",
    "import scipy\n",
    "import datetime \n",
    "\n",
    "import keras\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "K.tensorflow_backend._get_available_gpus()\n",
    "\n",
    "path_to_configs = \"../\"\n",
    "sys.path.append(path_to_configs)\n",
    "from configs import * \n",
    "from models import * \n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "sys.path.append(\"../../packages\")\n",
    "from IntegratedGradients import IntegratedGradients as IG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(path_to_configs + path_to_MDAD_data_folders + \"%s.h5\"%(full_pca_dataset), 'r') as hf:\n",
    "    PCA_components = hf[\"PCA_components_\"][:]\n",
    "    gene_symbols = hf[\"gene_symbols\"][:]\n",
    "    \n",
    "\n",
    "with h5py.File(path_to_configs + path_to_MDAD_data_folders + \"%s.h5\"%(full_dataset), 'r') as hf:\n",
    "    raw_X = hf[\"ge\"][:].astype(np.float64)      \n",
    "    raw_Y = hf[\"labels\"][:]\n",
    "    raw_gene_symbols = hf[\"gene_symbols\"][:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_layers(model_file, num_layers):\n",
    "    \n",
    "    # note: need to define custom functions for model in order to load, but these don't actually get used\n",
    "    model = keras.models.load_model(model_file, custom_objects={\"ordloss_cur_params\": ordloss(0), \\\n",
    "            \"ignorenans_mse\": ignorenans_mse, \"cat_acc\": ignorenans_categorical_accuracy(0), \\\n",
    "            \"ignorenans_scaled_mse\": ignorenans_scaled_mse})\n",
    "    \n",
    "    # define new model that cuts off the last several layers\n",
    "    newmodel = Model(inputs = model.input, outputs = model.layers[num_layers-1].output)\n",
    "    \n",
    "    # agian, need to specify these parameters, but they aren't used since we don't retrain the model\n",
    "    opt = optimizers.adam()  \n",
    "    newmodel.compile(optimizer=opt, loss= \"mse\")\n",
    "    \n",
    "    return newmodel\n",
    "\n",
    "\n",
    "def get_gene_weight_output(model, X):\n",
    "    L = model.output.shape[1] \n",
    "        \n",
    "    IG_L_by_N_by_G = np.zeros([L, len(X), len(gene_symbols)])\n",
    "\n",
    "    ig = IG.integrated_gradients(model)\n",
    "\n",
    "    for lvar in range(L):\n",
    "        if lvar%10 == 0:\n",
    "            print(lvar, datetime.datetime.now())\n",
    "            \n",
    "        IG_L_by_N_by_G[lvar] = np.array([ig.explain(x, outc=lvar) for x in X]) \n",
    "        \n",
    "    return IG_L_by_N_by_G \n",
    "\n",
    "\n",
    "\n",
    "def get_gene_weight_latent_node(model, X, node):\n",
    "    L = model.output.shape[1] \n",
    "        \n",
    "    IG_L_by_N_by_G = np.zeros([L, len(X), len(gene_symbols)])\n",
    "\n",
    "    ig = IG.integrated_gradients(model)\n",
    "    \n",
    "    node_weights =  np.array([ig.explain(x, outc=node) for x in X]) \n",
    "    return node_weights\n",
    "\n",
    "                \n",
    "def get_PCA_stacked_model(model, raw_X, method, fname):\n",
    "\n",
    "\n",
    "    main_input = Input(shape=(raw_X.shape[1],), dtype='float', name='main_input')\n",
    "    submean = Dense(raw_X.shape[1], activation=\"linear\", name='submean')(main_input)\n",
    "    pcatrans = Dense(num_components, activation=\"linear\", name='pcatrans')(submean)\n",
    "    model.layers.pop(0)\n",
    "    out_model = model(pcatrans)\n",
    "\n",
    "    if method == \"MTL\":\n",
    "        MTL_phenotype_output_mapping = {\"BRAAK\":0, \"CERAD\":1, \"PLAQUES\":2, \"TANGLES\":3, \"ABETA_IHC\":4, \"TAU_IHC\":5}\n",
    "        model_w_PCA = Model(inputs=[main_input], outputs=[out_model[MTL_phenotype_output_mapping[phenotype]]])\n",
    "    else:\n",
    "        model_w_PCA = Model(inputs=[main_input], outputs=[out_model])\n",
    "\n",
    "    model_w_PCA.layers[1].set_weights([np.identity(raw_X.shape[1]), -1*raw_X.mean(axis=0)])\n",
    "    model_w_PCA.layers[2].set_weights([PCA_components.T[:,:500], np.zeros(500)])\n",
    "\n",
    "\n",
    "    grad_clip_norm = float(fname.split(\"_\")[-2])\n",
    "    learning_rate = float(fname.split(\"_\")[-4])\n",
    "    opt = optimizers.adam(clipnorm=grad_clip_norm, lr=learning_rate)  \n",
    "    model_w_PCA.compile(optimizer=opt, loss = \"mse\")\n",
    "\n",
    "    return model_w_PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MTL_final_final_model = pickle.load(open(path_to_configs + path_to_final_models_chosen + \"MTL/final.p\", \"rb\" ) )\n",
    "baselines_final_final_model = pickle.load(open(path_to_configs + path_to_final_models_chosen + \"MLP_baselines/final.p\", \"rb\" ) )\n",
    "\n",
    "method = \"MTL\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENE WEIGHTS ON OUTPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(final_models_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_models_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************RUN 0*************\n",
      "---Saving IG weights for CERAD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nbbwang/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated output channel (0-based index): All\n",
      "Building gradient functions\n",
      "Progress: 100.0%\n",
      "Done.\n",
      "0 2021-01-16 04:33:22.844033\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-cf381cea6704>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mmodel_w_PCA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_PCA_stacked_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mIG_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_gene_weight_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_w_PCA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s%s/%s/%i/outputs/\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIG_save_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSPECIFIC_FOLDER\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-6837a75a7c28>\u001b[0m in \u001b[0;36mget_gene_weight_output\u001b[0;34m(model, X)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mIG_L_by_N_by_G\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlvar\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlvar\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mIG_L_by_N_by_G\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-6837a75a7c28>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mIG_L_by_N_by_G\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlvar\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlvar\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mIG_L_by_N_by_G\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bigdrive/AD_Project/IntegratedGradients/IntegratedGradients.py\u001b[0m in \u001b[0;36mexplain\u001b[0;34m(self, sample, outc, reference, num_steps, verbose)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tensorflow\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gradients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"theano\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gradients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m         \u001b[0mfetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m   2475\u001b[0m                               **self.session_kwargs)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mcandidate_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36mglobal_variables\u001b[0;34m(scope)\u001b[0m\n\u001b[1;32m   1245\u001b[0m     \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mobjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1246\u001b[0m   \"\"\"\n\u001b[0;32m-> 1247\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGLOBAL_VARIABLES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_collection\u001b[0;34m(key, scope)\u001b[0m\n\u001b[1;32m   4829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4831\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4832\u001b[0m   \"\"\"Wrapper for `Graph.get_collection()` using the default graph.\n\u001b[1;32m   4833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for i in range(100):\n",
    "method = \"MTL\"\n",
    "for i in range(100):\n",
    "    print(\"************RUN %i*************\"%i)\n",
    "    for phenotype in [\"CERAD\", \"BRAAK\", \"PLAQUES\", \"TANGLES\", \"ABETA_IHC\", \"TAU_IHC\"]:\n",
    "\n",
    "        print(\"---Saving IG weights for %s\"%phenotype)\n",
    "        if method == \"MTL\":\n",
    "            fname = MTL_final_final_model\n",
    "            path_to_model = final_models_save_path + \"models/MTL/ACT_MSBBRNA_ROSMAP_PCA/%s/%i/200.hdf5\"%(MTL_final_final_model,i)\n",
    "\n",
    "        else:\n",
    "            fname = baselines_final_final_model[phenotype]\n",
    "\n",
    "            path_to_model = final_models_save_path + \"models/MLP_baselines/%s/%s/%s/%i/200.hdf5\"%(\"ACT_MSBBRNA_ROSMAP_PCA\", phenotype, fname,i)\n",
    "        \n",
    "        model = keras.models.load_model(path_to_model, custom_objects={\"ordloss_cur_params\": ordloss(0), \\\n",
    "            \"ignorenans_mse\": ignorenans_mse, \"cat_acc\": ignorenans_categorical_accuracy(0), \\\n",
    "            \"ignorenans_scaled_mse\": ignorenans_scaled_mse})\n",
    "        \n",
    "        model_w_PCA = get_PCA_stacked_model(model, raw_X, method, fname)\n",
    "     \n",
    "        IG_weights = get_gene_weight_output(model_w_PCA, raw_X)\n",
    "\n",
    "        if not os.path.isdir(\"%s%s/%s/%i/outputs/\"%(IG_save_path, SPECIFIC_FOLDER,method,i)):\n",
    "            os.makedirs(\"%s%s/%s/%i/outputs/\"%(IG_save_path, SPECIFIC_FOLDER,method,i))\n",
    "\n",
    "        with h5py.File(\"%s%s/%s/%i/outputs/%s.h5\"%(IG_save_path, SPECIFIC_FOLDER,method,i,phenotype), 'w') as hf:\n",
    "            hf.create_dataset(\"gene_weights\", data=IG_weights)\n",
    "\n",
    "        K.clear_session()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(final_models_save_path + \"models/MLP_baselines/ACT_MSBBRNA_ROSMAP_PCA/TANGLES/200_relu_[500, 100]_[50, 10]_0.100000_0.000010_0.001000_[1, 1]_0.010000_20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(final_models_save_path + \"models/MTL/ACT_MSBBRNA_ROSMAP_PCA/200_relu_[500, 100]_[50, 10]_0.100000_0.001000_0.001000_[1, 1]_0.100000_20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "with h5py.File(\"%s%s/%s/%i/outputs/%s.h5\"%(IG_save_path, SPECIFIC_FOLDER,method, 0, \"CERAD\"), 'r') as hf:\n",
    "    tmp = hf[\"gene_weights\"][:]\n",
    "\n",
    "with h5py.File(\"/media/big/nbbwang/AD_Project/analyses/MTL_variable_tasks/6vars-continuous/IG_weights_stacked/%s/%s/%i/outputs/%s.h5\"%(SPECIFIC_FOLDER,method,0,\"CERAD\"), 'r') as hf:\n",
    "    tmp2 = hf[\"gene_weights\"][:]\n",
    "    \n",
    "tmp==tmp2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consensus nodes: Get IG weights for centroid nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nbbwang/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********CLUSTER NODE 0 (node 3 from run 99)******\n",
      "Evaluated output channel (0-based index): All\n",
      "Building gradient functions\n",
      "Progress: 100.0%\n",
      "Done.\n",
      "********CLUSTER NODE 1 (node 45 from run 0)******\n",
      "Evaluated output channel (0-based index): All\n",
      "Building gradient functions\n",
      "Progress: 100.0%\n",
      "Done.\n",
      "********CLUSTER NODE 2 (node 75 from run 95)******\n",
      "Evaluated output channel (0-based index): All\n",
      "Building gradient functions\n",
      "Progress: 100.0%\n",
      "Done.\n",
      "********CLUSTER NODE 3 (node 14 from run 31)******\n",
      "Evaluated output channel (0-based index): All\n",
      "Building gradient functions\n",
      "Progress: 100.0%\n",
      "Done.\n",
      "********CLUSTER NODE 4 (node 47 from run 89)******\n",
      "Evaluated output channel (0-based index): All\n",
      "Building gradient functions\n",
      "Progress: 100.0%\n",
      "Done.\n",
      "********CLUSTER NODE 5 (node 39 from run 72)******\n",
      "Evaluated output channel (0-based index): All\n",
      "Building gradient functions\n",
      "Progress: 100.0%\n",
      "Done.\n",
      "********CLUSTER NODE 6 (node 86 from run 83)******\n",
      "Evaluated output channel (0-based index): All\n",
      "Building gradient functions\n",
      "Progress: 100.0%\n",
      "Done.\n",
      "********CLUSTER NODE 7 (node 85 from run 4)******\n",
      "Evaluated output channel (0-based index): All\n",
      "Building gradient functions\n",
      "Progress: 100.0%\n",
      "Done.\n",
      "********CLUSTER NODE 8 (node 84 from run 32)******\n",
      "Evaluated output channel (0-based index): All\n",
      "Building gradient functions\n",
      "Progress: 100.0%\n",
      "Done.\n",
      "********CLUSTER NODE 9 (node 24 from run 13)******\n",
      "Evaluated output channel (0-based index): All\n",
      "Building gradient functions\n",
      "Progress: 100.0%\n",
      "Done.\n",
      "********CLUSTER NODE 10 (node 55 from run 92)******\n",
      "Evaluated output channel (0-based index): All\n",
      "Building gradient functions\n",
      "Progress: 100.0%\n",
      "Done.\n",
      "********CLUSTER NODE 11 (node 66 from run 93)******\n",
      "Evaluated output channel (0-based index): All\n",
      "Building gradient functions\n",
      "Progress: 100.0%\n",
      "Done.\n",
      "********CLUSTER NODE 12 (node 88 from run 81)******\n",
      "Evaluated output channel (0-based index): All\n",
      "Building gradient functions\n",
      "Progress: 100.0%\n",
      "Done.\n",
      "********CLUSTER NODE 13 (node 79 from run 47)******\n",
      "Evaluated output channel (0-based index): All\n",
      "Building gradient functions\n",
      "Progress: 100.0%\n",
      "Done.\n",
      "********CLUSTER NODE 14 (node 48 from run 18)******\n",
      "Evaluated output channel (0-based index): All\n",
      "Building gradient functions\n",
      "Progress: 100.0%\n",
      "Done.\n",
      "********CLUSTER NODE 15 (node 96 from run 55)******\n",
      "Evaluated output channel (0-based index): All\n",
      "Building gradient functions\n",
      "Progress: 100.0%\n",
      "Done.\n",
      "********CLUSTER NODE 16 (node 63 from run 84)******\n",
      "Evaluated output channel (0-based index): All\n",
      "Building gradient functions\n",
      "Progress: 100.0%\n",
      "Done.\n",
      "********CLUSTER NODE 17 (node 26 from run 6)******\n",
      "Evaluated output channel (0-based index): All\n",
      "Building gradient functions\n",
      "Progress: 100.0%\n",
      "Done.\n",
      "********CLUSTER NODE 18 (node 11 from run 18)******\n",
      "Evaluated output channel (0-based index): All\n",
      "Building gradient functions\n",
      "Progress: 100.0%\n",
      "Done.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-9cd53aa53133>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"********CLUSTER NODE %i (node %i from run %i)******\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mconsenus_IG_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_gene_weight_latent_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_w_PCA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0msavepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%sconsensus/%s/%s/last_shared/\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIG_save_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSPECIFIC_FOLDER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-6837a75a7c28>\u001b[0m in \u001b[0;36mget_gene_weight_latent_node\u001b[0;34m(model, X, node)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrated_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mnode_weights\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnode_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-6837a75a7c28>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrated_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mnode_weights\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnode_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bigdrive/AD_Project/IntegratedGradients/IntegratedGradients.py\u001b[0m in \u001b[0;36mexplain\u001b[0;34m(self, sample, outc, reference, num_steps, verbose)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# Or you can feed just a single numpy arrray.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0m_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintegrated_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinearly_interpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0msamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mnumsteps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bigdrive/AD_Project/IntegratedGradients/IntegratedGradients.py\u001b[0m in \u001b[0;36mlinearly_interpolate\u001b[0;34m(sample, reference, num_steps)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;31m# Calcuated stepwise difference from reference to the actual sample.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path_to_centroid_info = \"%s1/normed_KMeans_medoids/MTL_50_medoids_info.csv\"%final_rep_consensus_embeddings_savepath\n",
    "centroid_info = pd.read_csv(path_to_centroid_info).sort_values(\"cluster\")\n",
    "method = \"MTL\"\n",
    "\n",
    "consenus_IG_weights = np.zeros([len(centroid_info), len(raw_X), len(gene_symbols)])\n",
    "\n",
    "for i,row in centroid_info.iterrows():\n",
    "    run=row[\"run\"]\n",
    "    node_idx=row[\"node_idx\"]\n",
    "    \n",
    "    path_to_model = final_models_save_path + \"models/MTL/ACT_MSBBRNA_ROSMAP_PCA/%s/%i/200.hdf5\"%(MTL_final_final_model, run)\n",
    "    MTL_up_to_latent = get_model_layers(path_to_model, 4)\n",
    "    main_input = Input(shape=(raw_X.shape[1],), dtype='float', name='main_input')\n",
    "    submean = Dense(raw_X.shape[1], activation=\"linear\", name='submean')(main_input)\n",
    "    pcatrans = Dense(500, activation=\"linear\", name='pcatrans')(submean)\n",
    "    MTL_up_to_latent.layers.pop(0)\n",
    "    out_model = MTL_up_to_latent(pcatrans)\n",
    "    model_w_PCA = Model(inputs=[main_input], outputs=[out_model])\n",
    "    model_w_PCA.layers[1].set_weights([np.identity(raw_X.shape[1]), -1*raw_X.mean(axis=0)])\n",
    "    model_w_PCA.layers[2].set_weights([PCA_components.T[:,:num_components], np.zeros(500)])\n",
    "    grad_clip_norm = float(MTL_final_final_model.split(\"_\")[-2])\n",
    "    learning_rate = float(MTL_final_final_model.split(\"_\")[-4])\n",
    "    opt = optimizers.adam(clipnorm=grad_clip_norm, lr=learning_rate)  \n",
    "    model_w_PCA.compile(optimizer=opt, loss = \"mse\")\n",
    "\n",
    "    print(\"********CLUSTER NODE %i (node %i from run %i)******\"%(i, node_idx, run))\n",
    "\n",
    "    consenus_IG_weights[i] = get_gene_weight_latent_node(model_w_PCA, raw_X, node_idx)\n",
    "    \n",
    "    savepath = \"%sconsensus/%s/%s/last_shared/\"%(IG_save_path, SPECIFIC_FOLDER, method)\n",
    "    if not os.path.isdir(savepath):\n",
    "        os.makedirs(savepath)\n",
    "\n",
    "    with h5py.File(savepath + \"%i.h5\"%(i), 'w') as hf:\n",
    "        hf.create_dataset(\"gene_weights\", data=consenus_IG_weights[i])\n",
    "    \n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with h5py.File(\"/media/big/nbbwang/AD_Project/analyses/MTL_variable_tasks/6vars-continuous/IG_weights_stacked/%s/%s/%i/last_shared/%i.h5\"%(SPECIFIC_FOLDER, method,31,14), 'r') as hf:\n",
    "    tmp2 = hf[\"gene_weights\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with h5py.File(\"IG_weights_stacked2/consensus/%s/%s/last_shared/3.h5\"%(SPECIFIC_FOLDER, method), 'r') as hf:\n",
    "    tmp = hf[\"gene_weights\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1758, 14591)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
