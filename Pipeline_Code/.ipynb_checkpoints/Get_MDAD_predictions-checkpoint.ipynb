{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nbbwang/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras import optimizers, regularizers, losses\n",
    "\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras import metrics\n",
    "\n",
    "import scipy\n",
    "import datetime \n",
    "\n",
    "import keras\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "K.tensorflow_backend._get_available_gpus()\n",
    "\n",
    "from configs import * \n",
    "from models import * \n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "sys.path.append(\"/home/nbbwang/bigdrive/AD_Project/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MTL_phenotype_output_mapping = {\"BRAAK\":0, \"CERAD\":1, \"PLAQUES\":2, \"TANGLES\":3, \"ABETA_IHC\":4, \"TAU_IHC\":5}\n",
    "\n",
    "with h5py.File(path_to_MDAD_data_folders + \"%s.h5\"%(full_pca_dataset), 'r') as hf:\n",
    "    X = hf[\"ge_transformed\"][:,:num_components].astype(np.float64)      \n",
    "    Y = hf[\"labels\"][:]    \n",
    "    PCA_components = hf[\"PCA_components_\"][:]\n",
    "    gene_symbols = hf[\"gene_symbols\"][:]\n",
    "    labels_names = hf[\"labels_names\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.DataFrame(Y.astype(str), columns=labels_names.astype(str), dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MTL_final_final_model = pickle.load(open(path_to_final_models_chosen + \"MTL/final.p\", \"rb\" ) )\n",
    "method = \"MTL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_preds = \"../../Pipeline_Outputs_Submitted/final_model/MDAD_predictions/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get predictions for each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nbbwang/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../Pipeline_Outputs_Submitted/final_model/MDAD_predictions/0.hdf5\n",
      "1\n",
      "../../Pipeline_Outputs_Submitted/final_model/MDAD_predictions/1.hdf5\n",
      "2\n",
      "../../Pipeline_Outputs_Submitted/final_model/MDAD_predictions/2.hdf5\n",
      "3\n",
      "../../Pipeline_Outputs_Submitted/final_model/MDAD_predictions/3.hdf5\n",
      "4\n",
      "../../Pipeline_Outputs_Submitted/final_model/MDAD_predictions/4.hdf5\n"
     ]
    }
   ],
   "source": [
    "method = \"MTL\"\n",
    "for i in range(100):\n",
    "# for i in range(5): [for testing]\n",
    "    print(i)\n",
    "    fname = MTL_final_final_model\n",
    "    path_to_model = final_models_save_path + \"models/MTL/ACT_MSBBRNA_ROSMAP_PCA/%s/%i/200.hdf5\"%(MTL_final_final_model,i)\n",
    "\n",
    "    model = keras.models.load_model(path_to_model, custom_objects={\"ordloss_cur_params\": ordloss(0), \\\n",
    "        \"ignorenans_mse\": ignorenans_mse, \"cat_acc\": ignorenans_categorical_accuracy(0), \\\n",
    "        \"ignorenans_scaled_mse\": ignorenans_scaled_mse})\n",
    "\n",
    "\n",
    "    for j,layer in enumerate(model.layers[-len(phenotypes):]):\n",
    "        MTL_phenotype_output_mapping[layer.name[:-4]] = j\n",
    "\n",
    "    preds = model.predict(X)\n",
    "\n",
    "\n",
    "\n",
    "    if not os.path.isdir(path_to_preds):\n",
    "        os.makedirs(path_to_preds)\n",
    "\n",
    "    with h5py.File(\"%s%i.hdf5\"%(path_to_preds,i), 'w') as hf:\n",
    "        for phenotype in [\"CERAD\", \"BRAAK\", \"PLAQUES\", \"TANGLES\", \"ABETA_IHC\", \"TAU_IHC\"]:\n",
    "            hf.create_dataset(phenotype, data=preds[MTL_phenotype_output_mapping[phenotype]])\n",
    "    \n",
    "    print(\"%s%i.hdf5\"%(path_to_preds,i))\n",
    "    K.clear_session()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get consensus prediction (average over runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.hdf5\n",
      "3.hdf5\n",
      "1.hdf5\n",
      "4.hdf5\n",
      "2.hdf5\n"
     ]
    }
   ],
   "source": [
    "phenotypes = ['ABETA_IHC', 'BRAAK', 'CERAD', 'PLAQUES', 'TANGLES', 'TAU_IHC']\n",
    "preds_runs = []\n",
    "for f in os.listdir(path_to_preds):\n",
    "    if f.split(\".\")[0].isnumeric():\n",
    "        print(f)\n",
    "        preds =[]\n",
    "        for phenotype in phenotypes:\n",
    "            with h5py.File(path_to_preds + \"%i.hdf5\"%i, 'r') as hf:\n",
    "                preds.append(hf[phenotype][:])\n",
    "        preds_runs.append(np.array(preds))\n",
    "        \n",
    "        \n",
    "to_save_df = pd.DataFrame(np.mean(np.mean(np.array(preds_runs),axis=3),axis=0).T, columns=phenotypes)\n",
    "to_save_df[\"sample_name\"]  = labels[\"sample_name\"]\n",
    "to_save_df.to_csv(path_to_preds + \"CONSENSUS_PREDICTIONS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
