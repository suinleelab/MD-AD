{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get predictions from final models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nbbwang/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras import optimizers, regularizers, losses\n",
    "\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras import metrics\n",
    "\n",
    "import scipy\n",
    "import datetime \n",
    "\n",
    "import h5py\n",
    "import keras\n",
    "\n",
    "import sys\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import pickle\n",
    "\n",
    "\n",
    "import os\n",
    "sys.path.append(\"/home/nbbwang/bigdrive/AD_Project/\")\n",
    "from IntegratedGradients import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 18, 'font.family': \"Times New Roman\"})\n",
    "plt.rcParams[\"font.family\"] = \"Times\"\n",
    "\n",
    "\n",
    "import IntegratedGradients as IG\n",
    "import keras \n",
    "\n",
    "from scipy import stats \n",
    "\n",
    "\n",
    "path_to_configs = \"../\"\n",
    "sys.path.append(path_to_configs)\n",
    "from configs import *\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hy_dict_list = list(ParameterGrid(hyperparams))\n",
    "MTL_final_final_model = pickle.load(open(path_to_configs+path_to_final_models_chosen + \"MTL/final.p\", \"rb\" ) )\n",
    "baselines_final_final_model = pickle.load(open(path_to_configs+path_to_final_models_chosen + \"MLP_baselines/final.p\", \"rb\" ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phens = [\"CERAD\", \"BRAAK\", \"PLAQUES\", \"TANGLES\", \"ABETA_IHC\", \"TAU_IHC\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving consensus test predictions to ../../../md-ad_public_repo_data/External_Validation/predictions/amp-ad_msbb_mssm_affymetrixu133ab_parahippocampal gyrus_rspp-adj.tsv/MTL/200_relu_[500, 100]_[50, 10]_0.100000_0.001000_0.001000_[1, 1]_0.100000_20/\n",
      "Saving consensus predictions to ../../../md-ad_public_repo_data/External_Validation/predictions/amp-ad_msbb_mssm_affymetrixu133ab_parahippocampal gyrus_rspp-adj.tsv/MLP_baselines/\n",
      "Saving consensus test predictions to ../../../md-ad_public_repo_data/External_Validation/predictions/amp-ad_msbb_mssm_affymetrixu133ab_inferior temporal gyrus_rspp-adj.tsv/MTL/200_relu_[500, 100]_[50, 10]_0.100000_0.001000_0.001000_[1, 1]_0.100000_20/\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../../md-ad_public_repo_data/External_Validation/predictions/amp-ad_msbb_mssm_affymetrixu133ab_inferior temporal gyrus_rspp-adj.tsv/MTL/200_relu_[500, 100]_[50, 10]_0.100000_0.001000_0.001000_[1, 1]_0.100000_20/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e9718fab73f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saving consensus %s predictions to %s\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdset_to_check\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpath_to_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_preds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../../md-ad_public_repo_data/External_Validation/predictions/amp-ad_msbb_mssm_affymetrixu133ab_inferior temporal gyrus_rspp-adj.tsv/MTL/200_relu_[500, 100]_[50, 10]_0.100000_0.001000_0.001000_[1, 1]_0.100000_20/'"
     ]
    }
   ],
   "source": [
    "for dpath in [\"\", \"_intersection\"]:\n",
    "    for dset in os.listdir(\"%spredictions%s/\"%(path_to_ext_val_predictions, dpath)):\n",
    "        if dpath==\"_intersection\":\n",
    "            dsets_to_check = [\"train\",\"test\"]\n",
    "        else:\n",
    "            dsets_to_check = [\"test\"]\n",
    "\n",
    "            \n",
    "        ######### MD-AD AVERAGING ################\n",
    "        for dset_to_check in dsets_to_check:\n",
    "\n",
    "            all_pred_vals = []\n",
    "            if dset_to_check == \"train\":\n",
    "                path_to_preds = \"%spredictions%s/%s/MTL/%s/train/\"%(path_to_ext_val_predictions, dpath,dset, MTL_final_final_model)\n",
    "            else:\n",
    "                path_to_preds = \"%spredictions%s/%s/MTL/%s/\"%(path_to_ext_val_predictions, dpath,dset, MTL_final_final_model)\n",
    "            print(\"Saving consensus %s predictions to %s\"%(dset_to_check,path_to_preds))\n",
    "\n",
    "            for f in os.listdir(path_to_preds):\n",
    "                if os.path.isdir(path_to_preds + f):\n",
    "                    continue\n",
    "\n",
    "                pred_df = pd.read_csv(\"%s/%s\"%(path_to_preds,f), index_col=\"Unnamed: 0\")\n",
    "                all_pred_vals.append(pred_df.values)\n",
    "\n",
    "            final_preds = pd.DataFrame(np.mean(np.array(all_pred_vals),axis=0), columns=pred_df.columns)\n",
    "            if dset_to_check == \"train\":\n",
    "                final_preds.to_csv(\"%spredictions%s/%s/MTL/final_train.csv\"%(path_to_ext_val_predictions,dpath,dset))\n",
    "            else:\n",
    "                final_preds.to_csv(\"%spredictions%s/%s/MTL/final.csv\"%(path_to_ext_val_predictions, dpath,dset))\n",
    "                \n",
    "                \n",
    "        all_pred_vals = []\n",
    "\n",
    "        ############## MLP averaging #######################\n",
    "        path_to_preds = \"%spredictions%s/%s/MLP_baselines/\"%(path_to_ext_val_predictions, dpath,dset)\n",
    "        print(\"Saving consensus predictions to %s\"%path_to_preds)\n",
    "\n",
    "        for f in os.listdir(path_to_preds):\n",
    "            if f.split(\".\")[0] in [str(i) for i in range(100)]:\n",
    "                pred_df = pd.read_csv(\"%s/%s\"%(path_to_preds,f), index_col=\"Unnamed: 0\")\n",
    "                all_pred_vals.append(pred_df.values)\n",
    "\n",
    "        final_preds = pd.DataFrame(np.mean(np.array(all_pred_vals),axis=0), columns=pred_df.columns)\n",
    "        final_preds.to_csv(path_to_preds + \"final.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
