{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PACKAGES\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "mpl.rcParams['font.size']=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def str_to_param_dict(string):\n",
    "    d = {}\n",
    "    _,_,_,_,_,d[\"k_reg\"],d[\"learning_rate\"],_,d[\"grad_clip_norm\"],_ = string.split(\"_\")\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_results = \"/Users/nbbwang/Documents/Lee Lab/AD_project/analyses/MTL_variable_tasks/6vars-continuous/origGE/\"\n",
    "\n",
    "dtype = \"ACT_MSBBRNA_ROSMAP_PCASplit\"\n",
    "metric = \"loss\"\n",
    "\n",
    "blue_plot =(0.12156862745098039, 0.4666666666666667, 0.7058823529411765, 1.0)\n",
    "green_plot= (0.17254901960784313, 0.6274509803921569, 0.17254901960784313, 1.0)\n",
    "red_plot= (0.8392156862745098, 0.15294117647058825, 0.1568627450980392, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_CV_test_res_as_df(path_to_log_files):\n",
    "    firstfile = os.listdir(path_to_log_files)[0]\n",
    "    cols = pd.read_csv(path_to_log_files + firstfile).columns\n",
    "    \n",
    "    # save average performance of each CV fold for a given train/test split\n",
    "    training_averages = []\n",
    "    for i in range(5):\n",
    "        all_vals = np.array([pd.read_csv(path_to_log_files + \"%d.log\"%((i*5)+j)).values for j in range(5)])\n",
    "        training_averages.append(pd.DataFrame(np.nanmean(all_vals,axis=0), columns=cols))\n",
    "    # save average performance across all CV folds for each train/test split \n",
    "    # (this could be used to select the hyperparameters for the final model but not for model evaluation purposes!)\n",
    "    training_overall_averages = pd.DataFrame(np.nanmean(np.array([training_averages[i].values for i in range(5)]),axis=0), columns=cols)\n",
    "\n",
    "    # save test performance measures\n",
    "    test_runs = []\n",
    "    for cur_idx in range(25,30):\n",
    "        test_runs.append(pd.read_csv(path_to_log_files + \"%d.log\"%cur_idx))\n",
    "    test_overall_averages = pd.DataFrame(np.nanmean(np.array([test_runs[i].values for i in range(5)]),axis=0), columns=cols)\n",
    "\n",
    "    return training_averages, training_overall_averages, test_runs, test_overall_averages\n",
    "\n",
    "\n",
    "def get_CV_test_error(path_to_results_folder, datatype, var, metric, MTL=True):\n",
    "    \n",
    "    hy_names = []\n",
    "    tr_valid_vals_folds = []\n",
    "    \n",
    "    # loop through all hyperparameter combos\n",
    "    files = os.listdir(path_to_results_folder + datatype)\n",
    "    for fname in files:\n",
    "        if MTL:\n",
    "            cur_metric = var + \"_out_\" + metric\n",
    "            path_to_log_files = path_to_results_folder + datatype+ \"/\"+fname+\"/\"\n",
    "        else:\n",
    "            cur_metric = metric\n",
    "            path_to_log_files = path_to_results_folder + datatype+ \"/\"+fname+\"/\" + variable + \"/\"\n",
    "\n",
    "        # get training performances \n",
    "        tr_runs, tr_av, test_runs, test_av = get_CV_test_res_as_df(path_to_log_files)\n",
    "        \n",
    "        hy_names.append(fname) \n",
    "        # for each train/test split, get average average CV score for the current set of hyperparameters\n",
    "        tr_valid_vals_folds.append(np.array([tr_av_fold[\"val_\" + cur_metric].values[-1] for tr_av_fold in tr_runs]))\n",
    "\n",
    "\n",
    "    \n",
    "    best_cases_test_performances = []\n",
    "    best_case_test_performance_eps = []\n",
    "    best_cases_parameters = []\n",
    "\n",
    "    # get hyperparameter setting with lowest loss for each test fold \n",
    "    best_params_per_outerfold = np.argmin(np.array(tr_valid_vals_folds), axis=0)\n",
    "\n",
    "    # loop through the five final test performances we get for each train/test split \n",
    "    for i, bestidx in enumerate(best_params_per_outerfold):\n",
    "\n",
    "        if MTL:\n",
    "            best_path = path_to_results_folder + datatype+ \"/\"+hy_names[bestidx]+\"/\"\n",
    "        else:\n",
    "            best_path = path_to_results_folder + datatype+ \"/\"+hy_names[bestidx]+\"/\" + variable + \"/\"\n",
    "           \n",
    "        tr_runs, tr_av, test_runs, test_av = get_CV_test_res_as_df(best_path)\n",
    "\n",
    "        best_cases_test_performances.append(test_runs[i][\"val_\" + cur_metric].values[-1])\n",
    "        best_case_test_performance_eps.append(np.argmin(test_runs[i][\"val_\" + cur_metric]))\n",
    "        best_cases_parameters.append(hy_names[bestidx])\n",
    "\n",
    "    return best_cases_test_performances,best_case_test_performance_eps,best_cases_parameters\n",
    "\n",
    "\n",
    "\n",
    "def get_percent_error_reduction(performance_dict, orig, new, pathology):\n",
    "    return (performance_dict[orig][pathology] - performance_dict[new][pathology])/performance_dict[orig][pathology]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store val and test set variances for MSE scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_VARIANCES = {}\n",
    "TOTAL_VARIANCES = {}\n",
    "\n",
    "\n",
    "for variable in [\"CERAD\", \"BRAAK\", \"PLAQUES\", \"TANGLES\", \"ABETA_IHC\", \"TAU_IHC\"]:\n",
    "\n",
    "    vars_by_split = []\n",
    "    all_vals = np.array([])\n",
    "    for fold_idx in range(30):\n",
    "        path_to_preds_folder = path_to_results + \"predictions/MTL/\" + dtype + \"/\" \n",
    "        folder = os.listdir(path_to_preds_folder)[0]\n",
    "\n",
    "        with h5py.File(path_to_preds_folder  + folder+\"/\" + \"%d.h5\"%fold_idx, 'r') as hf:\n",
    "            true_plaques = hf[\"y_true\"][variable][:]\n",
    "        \n",
    "        all_vals = np.append(all_vals, true_plaques)\n",
    "        vars_by_split.append(np.nanvar(true_plaques))    \n",
    "    variances = np.array(vars_by_split)\n",
    "    ALL_VARIANCES[variable] = variances\n",
    "    \n",
    "    TOTAL_VARIANCES[variable] = np.nanvar(all_vals)\n",
    "    \n",
    "saved_vars = pd.DataFrame.from_dict(ALL_VARIANCES)\n",
    "saved_vars.to_csv(\"test_set_variances.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create dict of test set performances for each model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/nbbwang/Documents/Lee Lab/AD_project/analyses/MTL_variable_tasks/6vars-continuous/origGE/'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "PERFORMANCE_VALS = {}\n",
    "PERFORMANCE_VALS_list = {}\n",
    "PERFORMANCE_SEMS = {}\n",
    "best_hys = {}\n",
    "df_contents=[]\n",
    "\n",
    "for experiment in [\"MTL\", \"MLP_Baselines\", 'Linear_Baselines']:\n",
    "\n",
    "    PERFORMANCE_VALS[experiment] = {}\n",
    "    PERFORMANCE_VALS_list[experiment] = {}\n",
    "    PERFORMANCE_SEMS[experiment] = {}\n",
    "    best_hys[experiment] = {}\n",
    "\n",
    "    path_to_results_folder = path_to_results + \"results/\" + experiment + \"/\"\n",
    "    path_to_preds_folder = path_to_results + \"predictions/\" + experiment + \"/\"\n",
    "\n",
    "\n",
    "    for variable in [\"CERAD\", \"BRAAK\", \"PLAQUES\", \"TANGLES\", \"TAU_IHC\", \"ABETA_IHC\"]:\n",
    "\n",
    "        # get test results for each fold\n",
    "        best_hy_test, best_hy_ep, best_hy = get_CV_test_error(path_to_results_folder,\\\n",
    "                dtype, variable, metric, MTL=(experiment==\"MTL\"))\n",
    "\n",
    "        # get scaled average + std error for test performance\n",
    "        mean_performance = np.round(np.mean(best_hy_test/ALL_VARIANCES[variable][25:]), 5)\n",
    "        sem_performance = stats.sem(np.array(best_hy_test)/np.array(ALL_VARIANCES[variable][25:]))\n",
    "        \n",
    "        best_hys[experiment][variable] = best_hy\n",
    "        PERFORMANCE_VALS[experiment][variable] = mean_performance\n",
    "        PERFORMANCE_VALS_list[experiment][variable] = best_hy_test/ALL_VARIANCES[variable][25:]\n",
    "\n",
    "        PERFORMANCE_SEMS[experiment][variable] = sem_performance\n",
    "    \n",
    "        for i,x in enumerate(best_hy):\n",
    "            df_contents.append([experiment, variable, i] + list(str_to_param_dict(x).values()))\n",
    "            \n",
    "selected_hyperparams = pd.DataFrame(df_contents, columns=[\"experiment\", \"variable\", \"run\"]+list(str_to_param_dict(x).keys()))\n",
    "selected_hyperparams.to_csv(\"selected_hyperparameters.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put results into format for easily generating figures \n",
    "\n",
    "experiments = [\"Linear_Baselines\", \"MLP_Baselines\", \"MTL\"]\n",
    "\n",
    "VALUES = {}\n",
    "STD_ERRS = {}\n",
    "METRICS = {}\n",
    "\n",
    "for pathology in [\"CERAD\", \"BRAAK\"]:\n",
    "    VALUES[pathology] = []\n",
    "    STD_ERRS[pathology] = []\n",
    "    METRICS[pathology] = 'Mean Squared Error (scaled)'\n",
    "    for experiment in experiments:\n",
    "        VALUES[pathology].append(PERFORMANCE_VALS[experiment][pathology])\n",
    "        STD_ERRS[pathology].append(PERFORMANCE_SEMS[experiment][pathology])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate paper figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQMAAAFLCAYAAADS2unKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAVCklEQVR4nO3df7xtdV3n8dcbAfkhXBAkCwjkxi8H\nTOsOgjeRHzMMiTXmQ8IMEpok0segYk1OVErlY3IspMvI6M3kpuWoqeUYiCheMEWnbmb5gwuGHrRA\nDAKEC1xUPv2xvtu7OXP2OWufs++595z7ej4e+7HuXt+1vuu7N5z3/q61vmutVBWStNO2boCk7YNh\nIAkwDCQ1hoEkwDCQ1BgGkgDDQFJjGCwDSfZI8ktJPpTka0keTLIpyVeTvC/J2Ul2n7bOVJLq+Xr6\ntHWvn2GZR5Pcl+TvkrwxycFjtP9zQ/U8q8fyM23/kST/kmRjkvcmuSjJk/t/i4qDjpa2JD8BrAWG\n/8ffBDwK7DU073bgnKr6eFtvCjikLfvAHJs5taq+OLTN64HnAA8D97XZjwP2A9Lefws4o6o+OUf7\nnwb8/dCstVX1i3OsM9P2dwL2Bh4/tOh3gLcBv1xVm2arU/YMlrQk5wJ/QRcENwPnAPtX1ROqam9g\nH+CFwPXADwAnzlDN71XVk+d4fXGG9QDeM7TMk4A9gJ8B7qb7w3xXksePWHfg3DZ9G12AnZVkt37f\nwGO2f0BV7QZ8H/AC4BpgZ+AC4MYke81WkQyDJav9or6F7r/h1cAzqupPquruwTJVdV9Vvb+qTgbO\nAu7fmm2qqoer6t3AhW3WwcDJo5ZPsjPw4vb2jcANwArgPy+gDd+sqj+vqh8Hfh4o4Gl0YaNZGAZL\n1+vpusT/DLy4qh6abeGqei9w6WI0DLh26N9PnWW50+l+yTdU1S3An7b5L5lEI6rqSuD329szW4Bq\nBMNgCUpyIHBGe7umqu6bbfmBWrwDRBn69+NmWW7wR/+uNn0fsBk4Lcn3T6gtbwQeaW36mQnVuSwZ\nBkvTSWz5g/u/27Ado5w29O+vzLRAkn2Bn6A7TvBu6HZrgKvoAuRnJ9GQqvom8Lft7bMnUedyZRgs\nTUe36Wa6A4cL8ctJvjHL62N9K0qyW5IXAX/QZt0NfHjE4i+i281ZX1V3DM2f6K5C8/k2fcoE61x2\ndt7WDdC87Nem90yg679ne43yjVnKzkpyevv3TsD+bOmxPAycXVUPjlj33Db902nzrwLuBY5J8iNV\n9dlZtt/XPW36xAnUtWzZM9AlVZVZXk+fZd3BqbzvA57EliCYAo6pqmtmWinJUcBxdD2bDwyXVdVm\n4P3t7c/N+1PNzEE1szAMlqbB6cN9k2TWJbeuPx6EBvAE4FnAeuBQYG2SXUesN9gFuGrEwc9Bb+HF\nSXaZQDv3bdN7Zl1qB2cYLE03tenjgSO3ZUMGqmpTVX0aeC7dPvopwO9MXy7JTsDZ7e0LZhr+DHy8\nlT8J+PEJNO/YNp3xYKY6hsHSdANburw/uS0bMl1VPQy8sr19ZZIfmrbIqcBBY1S5oAOJSQ4AfrS9\n/auF1LXcGQZLUFX9E92oQ4D/mmTvPust1i5Fu/7hRmAX4HXTigd/3P+Hrvs+6rW6Lfe8JPsxf78C\n7EoXnu+aY9kdmmGwdP063QG4g+iuAZh1PH+SnwYuWoyGNW9s0xclWdnasBfwU23+e6vq3lleN9J1\n63elOw05tnbtxqvb23dX1Rfm/Wl2AIbBElVVnwNeTveLdwbwd+1S5e+dPkuyIskLkqwH3sNjr2Lc\n2j5INwbiccB/b/POpLuYaRPwkR51DM409N5VSLJ/kucnuRq4ku4Mx+eA8/vWscOqKl9L+AU8H7iT\nLhQGr/vpLiEenjcFnDi03lSb/wDdWILZXmdN2+b1bd11c7TtpW25R4AfZMuxjj/r+dmOH2r/0TNs\n/6GhNt7Z3g9/5keAK4A9tvV/p6XwctDREldVf5Hko3S/nmfQXaG3P1sCYAPdL+wHqjuHP91cg44A\ndp+jfJR3AL9Fd4n1/2bLcOAPjFzjsf4f3YVYB9J9vtdMK9+tvQC+TReCXwP+ge6Yxbuq6s55tn2H\nM9bNTZIcRPcf93S6UXB30F1Pf0lVzXkOt+3DXTnHYo9W1WwXt0jaCnqHQTsIdCNwAN3+4Ea6UWQn\n0+0brq6ha+lH1PF0um7tTJ5Nd276qqp6Xq9GSZqYcXYTrqALggur6vLBzCSXAq+iu77+gtkqqO6g\n1+dmKkvy6fbPtWO0SdKE9OoZJDkMuJVuH3RlVT06VLYX3e5CgANqHveaS3IM3ai1fwYOqarvjluH\npIXpe2rxlDa9djgIAKrqfuBTdKeMjp9nOwY3wPwjg0DaNvqGwWD8+y0jyr/cpkeM24B2C++z6W5y\n4X3qpG2kbxisaNNRt9cazN9nHm346bbeh6vq67MtmOT8JBvay9Fk0gRNagTiYMz7fK4XH4wMe+tc\nC1bV2qpaVVWr6G6eIWlC+obB4Jd/xYjyvact10uSp9JdAz984Y2kbaBvGAzuszfqmMDhbTrqmMIo\nHjiUthN9Ty2uBP6R2U8t7gQ8qe+pxXaV3e10vY1D5zpeMMP6G9rugqQJ6NUzqKpb6R6McSjdlXLD\nLqEb2/6OQRAk2SXJUYNLV0c4k+669avHDQJJkzfOCMSX0Q1HXpPkVLpbbz2TbjjyLcDFQ8se2Mpv\nowuQmQwOHDriUNoO9D6b0HoHq4B1dCHwamAlsAY4Ya7rEoYlORr4MTxwKG03luwj2T1mIE2WdzqS\nBBgGkhrDQBJgGEhqDANJgGEgqTEMJAGGgaTGMJAEGAaSGsNAEmAYSGoMA0mAYSCpMQwkAYaBpMYw\nkAQYBrNKsi7JrLeCSnJSkkpybo/6ppJcP6n2SZNkGAxpd3V+zizlByY5Osnq9ozImZbZOclJ7d+H\nJDl8puVa+aokox5MIy0qw+CxzgOuT/KxJMcNZiZ5YpL/SfeA2Q8A1wD/mOQCYJcti+Us4EvAdUmO\nAv4H8KUka5McNFTfUUneB/wN8N8W5ZNJc6mqJfkCNmyFOncHXkn3cJeie1xcAfcC3wGuBJ4CnASs\nHyobnn4W+MlW3/cDbwIeBB4CNgMPtLruBV4L7L2tv0tfvqrKuyOPqHsf4KN0t4aH7o/4+VV1zbTl\nLgZ+Z2jWOuDna9qXmuSHgeuA/dqsrwHPqaqpiTdemid3E4Yk2TXJLwGfpwuCb7WizcCHkrytHQc4\nIclH6YJg8LDZbwHnAn+T5Lmtvv3b7sWNdE+degTYRPeQmc8muTjJExbp40mzMgwe6zzgCrpjA8cD\nf97mH0b3sJizgQ8DHwOOoXvU3JltmVcCP0v3yLgPtWMGlwMXAe+me2jtHcAG4GnADXRh8mtb+0NJ\nfbib8Ng6dwFOrKrr2vt1wEuqKu39wXSPn9+P7pjFg+3MwXrgvKpaN1xHkkOB3apqY1t/CpiqqpPa\n++OBjVV17yQ/hzQf4zxrcdmrqm/T7duPKp/zAbHDdcx1TKCqPjNmE6Wtxp6BJMBjBpIaw0ASYBhI\nagwDSYBhIKkxDCQBhoGkxjCQBBgGkhqHI8/DXLdCGxhc0yAtBfYMJAH2DOZl+i/+oKdgT0BLmT0D\nSYBhIKkxDCQBhoF68oEyy59hoBn5QJkdj2GgUXygzI5mWz+4Yb4vtsJDVBbQluq+ym3flgl+Jh8o\ns4O9vAfiBCzncQY+UGbH4W6CZuQDZXY8hoFG8YEyOxh3EyZgOe4m+ECZHY/XJmhG5QNldjj2DCZg\nOfYMtOPxmIEkwDCQ1BgGkgDDQFJjGEgCDANJjWEgCTAMJDWOQNSC+AyJ5cOegSRgmfcMjv3jYxd1\nrPVibe/zL/n8dvMrO/0X36HZS5c9A0mAYSCpMQwkAYaBpMYwkAQYBpIaw0ASYBhIagwDSYBhIKkx\nDCQBhoGkxjCQBBgGkhrDQBIwZhgkOSjJ25PcnmRzkqkklyXZd9wNJ3l2kvcnuaPVdUeSaweP8Ja0\nuHrf3CTJSuBG4ADgg8BG4DjgFcDpSVZX1d096/p14LeBu4C/pHs89/7AM4CTgKv7fwRJkzDOnY6u\noAuCC6vq8sHMJJcCrwJeD1wwVyVJzqQLgo8BL6iq+6eV7zJGmyRNSK/dhCSHAacBU8CbpxW/FtgE\nnJNkzznq2Ql4A/Ag8OLpQQDfe4y3pEXW95jBKW16bVU9OlzQ/qA/BewBHD9HPc8CnkK3G3BPkjOS\n/GqSVyQ5YYx2S5qwvrsJR7bpLSPKv0zXczgCuG6Wev59m94JfBY4drgwySeAF1bVv/Rsl3o69DVX\nLerNYRdre1O/e4Y3Xp2Qvj2DFW1634jywfx95qjngDa9ANgd+A/AXsAxwEeAE4E/G7VykvOTbEiy\nge6Ao6QJmdQ4g0E6z/Vr8Lih5V9YVddV1QNV9UXgp4B/Ap4zapehqtZW1aqqWkV3JkLShPTdTRj8\n8q8YUb73tOVGuadNv1JVfz9cUFUPJfkI8F/oTll+umfbFt0Xzv1Cr/nHrDtmMZojTUTfnsHNbXrE\niPLD23TUMYXp9dw7onwQFrv3bJekCenbM1jfpqcl2Wn4jEKSvYDVwEPAZ+ao5xPAd4DDk+xaVY9M\nKx/8lE71bNc24S++lqNePYOquhW4FjgUePm04kuAPYF3VNUm6AYOJTmqjVocrucu4D10uxu/OVyW\n5D8C/4luV+OasT+JpAUZZwTiy+iGI69JcipwE/BM4GS63YOLh5Y9sJXfRhcgwy5q612c5ETgr4FD\n6A4gfhd4aVWN2o2QtJX0PpvQegergHV0f8yvBlYCa4AT+l6XUFXfbOu/CTgYuJBuUNNVwLOrauSp\nRUlbz1hPYa6qrwPn9Vhuii2nG2cq/1e6HsJF42xf0tbj/QwkAYaBpMYwkAQYBpIaw0ASMObZBEmj\nJel12XZVbZeXXdszkATYM5AmZvov/qCnsL32BKazZyAJMAwkNYaBJMBjBlqg297wvF7zD/nVv1yM\n5mgB7BlIAuwZaIH8xV8+7BlIAgwDSY1hIAkwDCQ1hoEkwDCQ1BgGkgDDQFJjGEgCDANJjWEgCTAM\nJDWGgSTAMJDUeAmzdjg3HXV0r1uaL7XtHb3xpgXdeNWegSTAMJDUGAaSAMNAUmMYSAIMA0mNYSAJ\nMAwkNYaBJMAwkNQYBpIAw0BSYxhIAgwDSY1hIAkwDCQ1hoEkwDCQ1BgGkgDDQFLjDVGlCXnqzRt7\nzf/SkUctRnPGZs9AEmDPQJqY7fUXvy97BpIAw0BSYxhIAgwDSY1hIAkwDCQ1hoEkwDCQ1BgGkgDD\nQFJjGEgCDANJjWEgCTAMJDWGgSTAMJDUGAaSAMNAUmMYSAIMA0mNYSAJMAwkNYaBJMAwkNQYBpIA\nw0BSYxhIAsYMgyQHJXl7ktuTbE4yleSyJPuOUcdUkhrx+sb4H0HSJPR+8GqSlcCNwAHAB4GNwHHA\nK4DTk6yuqrt7VncfcNkM8x/o2x5JkzXOU5ivoAuCC6vq8sHMJJcCrwJeD1zQs657q+p1Y2xb0lbW\nazchyWHAacAU8OZpxa8FNgHnJNlzoq2TtGj69gxOadNrq+rR4YKquj/Jp+jC4njguh71PT7J2cAP\n0gXJPwCfqKrv9myPpAnrGwZHtuktI8q/TBcGR9AvDJ4MvHPavK8mOa+qbujZJkkT1Pdswoo2vW9E\n+WD+Pj3quhI4lS4Q9gSOBd4KHAp8OMkPj1oxyflJNiTZAOzfY1uSeprUOIO0ac21YFVdUlUfr6o7\nq+rBqvpCVV0AXArsDrxulnXXVtWqqloF3DWJhkvq9A2DwS//ihHle09bbj7e0qYnLqAOSfPUNwxu\nbtMjRpQf3qajjin08c029YyEtA30DYP1bXpaksesk2QvYDXwEPCZBbTlhDb9ygLqkDRPvcKgqm4F\nrqU7yPfyacWX0P2av6OqNgEk2SXJUW3U4vck+XdJnji9/iSHAP+rvf2TsT6BpIkYZwTiy+iGI69J\ncipwE/BM4GS63YOLh5Y9sJXfRhcgA2cCr0myHvgqcD+wEjgD2A24Gvi9+XwQSQvTOwyq6tYkq4Df\nAk4HngvcAawBLqmqf+1RzXq6MQvPoNst2BO4F/gk3biDd1bVnGckJE3eOD0DqurrwHk9lptiy+nG\n4fk3AA4qkrZD3s9AEmAYSGoMA0mAYSCpMQwkAYaBpMYwkAQYBpIaw0ASYBhIagwDSYBhIKkxDCQB\nhoGkxjCQBBgGkhrDQBJgGEhqDANJgGEgqTEMJAGGgaTGMJAEGAaSGsNAEmAYSGoMA0mAYSCpMQwk\nAYaBpMYwkAQYBpIaw0ASYBhIagwDSYBhIKkxDCQBhoGkxjCQBBgGkhrDQBJgGEhqDANJgGEgqTEM\nJAGGgaTGMJAEGAaSGsNAEmAYSGoMA0mAYSCpMQwkAYaBpMYwkAQYBpIaw0ASYBhIagwDSYBhIKkx\nDCQBhoGkxjCQBBgGkhrDQBJgGEhqDANJgGEgqTEMJAGGgaTGMJAEGAaSGsNAEmAYSGoMA0mAYSCp\nMQwkAYaBpGasMEhyUJK3J7k9yeYkU0kuS7LvfBuQ5Jwk1V6/MN96JC3Mzn0XTLISuBE4APggsBE4\nDngFcHqS1VV19zgbT3IwcDnwAPCEcdaVNFnj9AyuoAuCC6vq+VX1mqo6BXgTcCTw+nE2nCTAlcDd\nwFvGWVfS5PUKgySHAacBU8CbpxW/FtgEnJNkzzG2fSFwCnBeW1/SNtS3Z3BKm15bVY8OF1TV/cCn\ngD2A4/tUluRo4HeBP6iqT/Rsg6StqG8YHNmmt4wo/3KbHjFXRUl2Bt4JfA34tZ7bl7SV9T2AuKJN\n7xtRPpi/T4+6fhN4BvBjVfVQz+0DkOR84Pz29sgkG+ZY5W/HqX+B9gfuWowN5dw5P/dMlud38Qb8\nLgbm/nsAuKuqTp+poPfZhLma0aY160LJcXS9gd+vqk+Pu5GqWgusHb95W1+SDVW1alu3Y3vgd7HF\nUvou+u4mDH75V4wo33vacv+fod2DW4Df6LldSYukbxjc3Kajjgkc3qajjilAN47gCOBo4OGhgUZF\nd0YC4A/bvMt6tkvShPTdTVjfpqcl2Wn4jEKSvYDVwEPAZ2apYzPwRyPKfoTuOMIn6YJn7F2I7cB2\nufuyjfhdbLFkvotUzbqbv2XB5CN0Yw0urKrLh+ZfCrwKeGtVXdDm7QKsBL5dVbf2qPt1dL2Dl1bV\n28b9EJIWbpwDiC+jG468JsmpwE3AM4GT6XYPLh5a9sBWfhtw6ERaKmmr6j0cuf3CrwLW0YXAq+l+\n/dcAJ4x7XYKk7Uvv3QRJy5v3M5AEGAaSGsNAEmAYSGoMA0mAYSCpMQwkAYaBpMYwkAQYBpKafwNe\nxi5Iv63p+AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 288x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQMAAAFLCAYAAADS2unKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSCoMA0mAYSCpMAwkAYaBpOL/AEcfIrFxT4gFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 288x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "methods = ['Linear \\nBaseline', 'MLP \\nBaseline', 'MD-AD']\n",
    "barcolor = plt.cm.Reds(.6)\n",
    "\n",
    "\n",
    "x_pos = np.arange(len(methods))\n",
    "\n",
    "# can use this code to try to generate upper limits for graph automatically\n",
    "ylims = {}\n",
    "for key in VALUES.keys():\n",
    "\n",
    "    VAL_plus_STD = np.array(VALUES[key]) + np.array(STD_ERRS[key])\n",
    "    upperlim = np.round(np.max(VAL_plus_STD), 1) \n",
    "    if key == \"ABETA_IHC\":\n",
    "        upperlim += .05\n",
    "    ylims[key] = (.4, upperlim)\n",
    "    \n",
    "# manually picked these upper limits for graph to make the figures look nice & clean\n",
    "ylims = {\"ABETA_IHC\": 1.2, \"TAU_IHC\": 1.1, \"PLAQUES\": .7, \"TANGLES\": 1.5, \"CERAD\": .7, \"BRAAK\": .7}\n",
    "\n",
    "\n",
    "for key in VALUES.keys():\n",
    "    \n",
    "    # generate annotations to test for significance between MTL and baselines \n",
    "    annots = []\n",
    "    for exp in [\"Linear_Baselines\", \"MLP_Baselines\"]:\n",
    "        t,p = stats.ttest_rel(PERFORMANCE_VALS_list[\"MTL\"][key], PERFORMANCE_VALS_list[exp][key])\n",
    "        if p/2 < .001:\n",
    "            annots.append(\"***\")\n",
    "        elif p/2 < .01:\n",
    "            annots.append(\"**\")\n",
    "        elif p/2 < .05:\n",
    "            annots.append(\"*\")\n",
    "        else:\n",
    "            annots.append(\"\")\n",
    "\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(4,5))\n",
    "    lin,mlp, mtl= ax.bar(x_pos, VALUES[key], yerr=STD_ERRS[key], align='center', alpha=1,  ecolor='black',\n",
    "                         color=[green_plot, blue_plot, red_plot],error_kw=dict(lw=2, capsize=5, capthick=2))\n",
    "\n",
    "    for i, txt in enumerate(annots):\n",
    "        ann_x = x_pos[i]\n",
    "        ann_y = VALUES[key][i] + STD_ERRS[key][i] + np.max(VALUES[key][i] + STD_ERRS[key][i])/100\n",
    "        ax.text(ann_x,ann_y, txt, color='black', horizontalalignment =\"center\",fontweight=\"bold\")\n",
    "    \n",
    "    for b in [lin,mlp,mtl]:\n",
    "        b.set_edgecolor(\"None\")\n",
    "            \n",
    "    \n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(\"\")\n",
    "    ax.set_ylim(.4,ylims[key])\n",
    "\n",
    "\n",
    "\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    if key in [\"BRAAK\", \"CERAD\", \"PLAQUES\"]:\n",
    "        ax.yaxis.set_major_locator(plt.MaxNLocator(3))\n",
    "    else:\n",
    "        ax.yaxis.set_major_locator(plt.MaxNLocator(4))\n",
    "\n",
    "    ax.set_facecolor('None')\n",
    "    ax.set_title(key)\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# calculating improvement percents:\n",
    "This is for the paper, if we want to say \"'MD-AD' provides a X percent reduction in error over the linear/mlp metod\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06726099394584531\n",
      "0.1293861045660066\n",
      "0.07450307450307449\n",
      "0.24846995416979\n",
      "0.09759229880963945\n",
      "0.1374034218080196\n"
     ]
    }
   ],
   "source": [
    "for p in [\"CERAD\", \"BRAAK\", \"PLAQUES\", \"TANGLES\", \"ABETA_IHC\", \"TAU_IHC\"]:\n",
    "    print(get_percent_error_reduction(PERFORMANCE_VALS, \"MLP_Baselines\", \"MTL\", p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10126764852000845\n",
      "0.12433947157726197\n",
      "0.06668803076430058\n",
      "0.3278938927216721\n",
      "0.17380865338062812\n",
      "0.2711839054670555\n"
     ]
    }
   ],
   "source": [
    "for p in [\"CERAD\", \"BRAAK\", \"PLAQUES\", \"TANGLES\", \"ABETA_IHC\", \"TAU_IHC\"]:\n",
    "    print(get_percent_error_reduction(PERFORMANCE_VALS, \"Linear_Baselines\", \"MTL\", p))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
