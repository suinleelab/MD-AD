{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "import matplotlib.patches as mpatches\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import os\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "from matplotlib import cm\n",
    "import copy\n",
    "%matplotlib inline\n",
    "from scipy import stats\n",
    "import sys\n",
    "import plotting_functions\n",
    "from tsne_plotting_functions import plot_continuous_tsne, plot_categorical_tsne\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes = [\"CERAD\", \"BRAAK\", \"PLAQUES\", \"TANGLES\", \"ABETA_IHC\", \"TAU_IHC\"]\n",
    "\n",
    "# # normed:\n",
    "path_to_MDAD_labels = \"../../DATA/MTL_data/labels.csv\"\n",
    "MDAD_labels = pd.read_csv(path_to_MDAD_labels)\n",
    "\n",
    "# merged covars:\n",
    "merged_covars = pd.read_csv('../../DATA/MTL_data/merged_phenotypes_w_apoe.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available variables:\n",
    "\n",
    "- Mayo:   Diagnosis, Tissue, Gender, AgeAtDeath, ApoE, PMI, RIN\n",
    "- HBTRC:   region (different files), disease, age, gender, pmi, ph, rin\n",
    "- MSBB array:  region (different files), PMI, pH, Sex, Race, Age, CDR (Braak\tNP1\tPLQ_Mn\tNPrSum\tNTrSum)\n",
    "- ACT:  structure_acronym, gender, race, white, education, autopsyage, anydementia, anyad????, apoe_raw, \n",
    "- ROSMAP: cogdx, age_death, educ, msex, race, spanish, apoe_genotype, ad_reagan, \n",
    "- MSBB RNA: BrodmannArea, RIN, PMI, RACE, AOD, CDR, SEX, NP.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_continuous(var, dset, dset_to_compare):\n",
    "    if var in phenotypes:\n",
    "        df1 = MDAD_labels[MDAD_labels[\"filename\"]==dset]\n",
    "        df2 = MDAD_labels[MDAD_labels[\"filename\"]==dset_to_compare]\n",
    "    else:\n",
    "        df1 = merged_covars[merged_covars[\"filename\"]==dset]\n",
    "        df2 = merged_covars[merged_covars[\"filename\"]==dset_to_compare]\n",
    "\n",
    "   \n",
    "    vals1 = df1[var].dropna().values.astype(float)\n",
    "    vals2 = df2[var].dropna().values.astype(float)\n",
    "    \n",
    "    annot = dset_to_compare[0]\n",
    "    if len(vals1)>0 and len(vals2)>0:\n",
    "        t,p = stats.ttest_ind(vals1,vals2)\n",
    "        p_stars = annot*3 if p<.001 else annot*2 if p <.01 else annot if p < .05 else \"\"\n",
    "    else:\n",
    "        p_stars = \"\"\n",
    "    \n",
    "    return(p_stars)\n",
    "\n",
    "\n",
    "\n",
    "def compare_categorical(var, dset, dset_to_compare):\n",
    "\n",
    "    df1 = merged_covars[merged_covars[\"filename\"]==dset]\n",
    "    df2 = merged_covars[merged_covars[\"filename\"]==dset_to_compare]\n",
    "\n",
    "    vals1 = df1[var]\n",
    "    vals2 = df2[var]\n",
    "    unique_vals = np.unique(np.hstack([vals1.dropna().values, vals2.dropna().values]))\n",
    "    \n",
    "    if len(vals1.dropna().values)==0 or len(vals2.dropna().values)==0:\n",
    "        return(\"\")\n",
    "\n",
    "    annot = dset_to_compare[0]\n",
    "    \n",
    "    \n",
    "     # create dictionary of counts for observed values of feature\n",
    "    valcounts1 = {}\n",
    "    for i,v in enumerate(vals1.value_counts().index):\n",
    "        valcounts1[v] = vals1.value_counts().values[i]\n",
    "    valcounts2 = {}\n",
    "    for i,v in enumerate(vals2.value_counts().index):\n",
    "        valcounts2[v] = vals2.value_counts().values[i]\n",
    "\n",
    "    for v in unique_vals:\n",
    "        if v not in valcounts1.keys():\n",
    "            valcounts1[v]=0\n",
    "        if v not in valcounts2.keys():\n",
    "            valcounts2[v]=0            \n",
    "\n",
    "    #get union of all values seen (just in case one of the groups has some 0s for some values)\n",
    "    all_vals = np.union1d(list(valcounts1.keys()), list(valcounts2.keys()))\n",
    "\n",
    "    # generate contingency table (shape: values observed x groups)\n",
    "    contingency_table = np.array([[valcounts1[elt], valcounts2[elt]] for elt in all_vals])\n",
    "\n",
    "    chi2_stat, p, dof, ex = stats.chi2_contingency(contingency_table)\n",
    "    p_stars = annot*3 if p<.001 else annot*2 if p <.01 else annot if p < .05 else \"\"\n",
    "    \n",
    "    return p_stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_show = {\n",
    "    \"BINARY\":[\"dementia\", \"sex_m\", \"race_w\"],\n",
    "    \"CATEGORICAL\":[\"addx_to_death_cats\", \"region\", \"apoe\"],\n",
    "    \"CONTINUOUS\":[\"RIN\", \"PMI_hours\", \"age_censored\", \"edu\"],\n",
    "    \"MD-AD_PHENOTYPE\": phenotypes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dementia,48.19 MMM  ,59.27 AAA RRR ,42.80  MMM ,\n",
      "sex_m,62.31 MMM RRR ,36.63 AAA  ,37.08 AAA  ,\n",
      "race_w,97.63 MMM  ,80.09 AAA RRR ,98.52  MMM ,\n",
      "\n",
      "addx_to_death_cats,(0.0/1.0/2.0/3.0) 60.8/12.8/16.0/10.4   ,()    ,(0.0/1.0/2.0/3.0) 56.1/16.1/17.2/10.7   ,\n",
      "region,(FWM/HIP/PCx/TCx) 24.6/24.9/24.0/26.4 MMM RRR ,(BM10/BM22/BM36/BM44) 27.8/25.8/22.8/23.7 AAA RRR ,(DLPFC) 100.0 AAA MMM ,\n",
      "apoe,(23.0/24.0/33.0/34.0/44.0) 8.0/1.3/70.5/18.9/1.3 MMM R ,(22.0/23.0/24.0/33.0/34.0/44.0) 1.2/11.7/0.7/55.0/29.2/2.1 AAA RR ,(22.0/23.0/24.0/33.0/34.0/44.0) 0.9/13.1/2.2/61.1/21.8/0.9 A MM ,\n",
      "\n",
      "RIN,6.35 +- 1.07 MMM  ,6.84 +- 1.47 AAA  ,nan +- nan   ,\n",
      "PMI_hours,nan +- nan   ,7.10 +- 5.33   ,7.16 +- 4.84   ,\n",
      "age_censored,86.97 +- 4.08 MMM  ,83.30 +- 7.52 AAA RRR ,86.55 +- 4.61  MMM ,\n",
      "edu,14.31 +- 3.13  RRR ,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/gws/nbbwang/anaconda3/envs/py36-test2/lib/python3.7/site-packages/ipykernel_launcher.py:24: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan +- nan   ,16.51 +- 3.49 AAA  ,\n",
      "\n",
      "CERAD,1.49 +- 1.08 (0.00-3.00) M  ,1.66 +- 1.28 (0.00-3.00) A  ,1.61 +- 1.16 (0.00-3.00)   ,\n",
      "BRAAK,3.45 +- 1.67 (0.00-6.00)   ,3.68 +- 1.86 (0.00-6.00)   ,3.37 +- 1.28 (0.00-6.00)   ,\n",
      "PLAQUES,NA,8.05 +- 8.79 (0.00-42.00)   ,0.73 +- 0.79 (0.00-4.96)   ,\n",
      "TANGLES,NA,NA,0.55 +- 0.73 (0.00-6.17)   ,\n",
      "ABETA_IHC,0.02 +- 0.02 (0.00-0.09)   ,NA,4.72 +- 5.21 (0.00-26.31)   ,\n",
      "TAU_IHC,0.02 +- 0.03 (0.00-0.11)  RRR ,NA,1.44 +- 5.68 (0.00-89.87) AAA  ,\n"
     ]
    }
   ],
   "source": [
    "for vartype in vars_to_show.keys():\n",
    "\n",
    "    for var in vars_to_show[vartype]:\n",
    "        print()\n",
    "        print(var, end=\",\")\n",
    "        for dset, df in merged_covars.groupby(\"filename\"):\n",
    "            phens_df = pd.read_csv(\"../../DATA/MTL_data/samples_neuropath_prenorm/%s\"%dset, delimiter=\"\\t\")\n",
    "\n",
    "            if vartype==\"BINARY\":\n",
    "                print(\"%.2f\"%(np.mean(df[var])*100), end = ' ')\n",
    "                for other_dset in np.setdiff1d(np.unique(merged_covars[\"filename\"]), dset):\n",
    "                    print(compare_categorical(var, dset, other_dset), end=' ')\n",
    "                print(\"\",end=\",\")\n",
    "\n",
    "            elif vartype==\"CATEGORICAL\":\n",
    "                vals,counts=np.unique(df[var].dropna(), return_counts=True)\n",
    "                print(\"(%s) %s\"%(\"/\".join(vals.astype(str)), \n",
    "                                    \"/\".join(np.round(counts/(np.sum(counts))*100,1).astype(str))),  end = ' ')\n",
    "                \n",
    "                for other_dset in np.setdiff1d(np.unique(merged_covars[\"filename\"]), dset):\n",
    "                    print(compare_categorical(var, dset, other_dset), end=' ')\n",
    "                print(\"\",end=\",\")\n",
    "            elif vartype==\"CONTINUOUS\":\n",
    "                print(\"%.2f +- %.2f\"%(np.nanmean(df[var]), np.nanstd(df[var])), end = ' ')\n",
    "                \n",
    "                for other_dset in np.setdiff1d(np.unique(merged_covars[\"filename\"]), dset):\n",
    "                    print(compare_continuous(var, dset, other_dset), end=' ')\n",
    "                print(\"\",end=\",\")\n",
    "    #         elif vartype==\"DUMMIES\":\n",
    "    #             print(\"%s %.2f +- %.2f\"%(var, np.nanmean(df[var]), np.nanstd(df[var])))\n",
    "            elif vartype==\"MD-AD_PHENOTYPE\":\n",
    "                if var in phens_df.columns:\n",
    "                    print(\"%.2f +- %.2f (%.2f-%.2f)\"%(np.nanmean(phens_df[var]), np.nanstd(phens_df[var]),\n",
    "                                            np.nanmin(phens_df[var]), np.nanmax(phens_df[var])), end = ' ')\n",
    "                    for other_dset in np.setdiff1d(np.unique(merged_covars[\"filename\"]), dset):\n",
    "                        print(compare_continuous(var, dset, other_dset), end=' ')\n",
    "                    print(\"\",end=\",\")\n",
    "                else:\n",
    "                    print(\"NA\", end = ',')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36-test2]",
   "language": "python",
   "name": "conda-env-py36-test2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
